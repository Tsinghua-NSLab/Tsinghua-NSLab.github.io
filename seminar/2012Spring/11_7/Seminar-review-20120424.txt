Information[edit]Topic:
1) Understanding Network Failures in Data Centers Measurement, Analysis, and Implications
2) Open Networking Summit 2012
Attendee:
Jun Li, Yibo Xue, Zhen Chen, Yaxuan Qi, Baohua Yang, Kai Wang, Xiang Wang, Feng Xie, Zhenlong Yuan, Yiyang Shao, Yang Gao, Zhi Liu, Xiaoqi Ren, Lu Li, Qing Xu, Yang Wu, Jingjie Jiang
Speaker: Zhi Liu and Yaxuan Qi
Recorder: Xiang Wang
Presentation[edit]Goal
	understand network failure
	improve reliabilityContribution
	first large-scale empirical study of network failures across multiple DCsKey chanllenge
	how to extract failures of interest?Steps
	Defining failures and Inconsistency: device & link failure
	Reconstruct and refine
	Identify failures with impactAnalysis
	Visualization of failure: service element update, component fialure
	Probability of device failure: LB(software and config error), Agg, ToR
	Which device casuse most failure(considering failure and downtime): LB(failures) and ToR(downtime)Conclusion
	Datacenter networks have high reliability
	Low-cost switches exhibit high reliability
	Load balancers are subject to transient faults
	Failures may lead to loss of small packetsFuture
	Study application level failures and their causes
	Further study of redundancy effectivenessDiscussion
	Q: system down really means link down? How to detect system down?
	Q: aggre failure probability higher than ToR, why? A: ToR has higher total number
	Q: high-layer redundancy is more effective than low-layer redundancy, why? A: low-layer device impact on small range elements
Open Networking Summit 2012[edit]Urs/Amin: Google Backbone uses OpenFlow
Rexford: APP-ID socket
Nick: SDN, S is software
Ward: App-aware Net, Net-aware APP
Beesley: QFabric may help
NTT/NEC: vDC migration, Fast Reconstruct
BigSwitch: OpenSDN, OpenController
Nicira: Overlay
New Concepts
everything can be changed
keep it simple
network security in rack(agile and dynamic)