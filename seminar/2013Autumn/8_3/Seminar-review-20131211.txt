Overview[edit]Title: GPU Acceleration of Regular Expression Matching for Large Datasets: Exploring the Implementation Space
Source: ACM International Conference on Computing Frontiers, 2013
Attendee: Prof. Xue, Zhen Chen, Kai Wang, Feng Xie, Xiang Wang, Yiyang Shao, Zhenlong Yuan, Zhe Fu, Chang Chen, Xiaohe Hu, Group of Prof. Xue
Speaker: Zhe Fu
Recorder: Chang Chen
Presentation[edit]Authors
Xiaodong Fu, Michela BecchiBackground
Regular Expression Matching, NFA vs. DFA
Implementation categories: memory-based vs. logic-based
DFA & Memory based solutions
GPU implementation: Streaming Multiprocessors, memory hierarchy...
Recent works: coarse-grained block level parallelism, Gnort, XFA -> GPU, iNFAnt
Evaluate GPU designs on practical datasets
General-Purpose computing on a Graphics Processing Unit (GPGPU), Compute Unified Device Architecture (CUDA)
CPU vs. GPU: task vs. data parallelism, floating-point operations per second, memory bandwidth
GPU architecture: kernel, grid, block, thread... memory
CUDA SummaryNFA-based Design
iNFAnt: inefficiency. On large NFAs, transition list can be very long and may require a large number of thread-block iterations; in most traversal steps, only a minority of the NFA states are active.
Optimized NFA: Optimization 1, 2, 3DFA-based Design
Uncompressed DFA-based solution
Compressed DFA-based solution
Enhanced compressed DFA-based solutionExperimental Evaluation
Data sets and platform: Intel Xeon E5620 CPU; an NVIDIA GTX 480 GPU
Performance evaluation: Thoughput, Effect of number of flows/SM on performance, Effect of cachingConclusion
A comprehensive study of regular expression matching on GPUs
Data sets of practical size and complexity
Explored advantages and limitations of different NFA- and DFA-based representations
Uncompressed DFA solution outperforms other implementations
On large and complex datasets exceeding the memory capacity
Schemes to improve a basic default-transition compressed DFA designQuestion[edit]Prof. Xue: GPU做法是否靠谱？GPU适合处理pipeline，适合加速高性能计算，而正则的工作主要在于查表。文章为什么不用GPU和FPGA比，只和CPU比。到底是否适合做？
Kyle：GPU工作四年前就开始。
Prof. Xue：GPU本身并行化强，有总够多的计算单元，为什么还要grouping？	
Kyle：并不是提出grouping方法，而是要探索GPU结构，做优化。贡献在于针对GPU结构，让它更好并行，并不是说一个cycle中把所有block都利用起来。
Prof. Xue：应该考虑GPU这个架构适合做什么？比如国防科大某教授，用GPU做了很多算法。Yiyang：文章有没有比较每美元计算能力？
Prof. Xue：比FPGA便宜，但性能差不少。Xiang：GPU和CPU性能优化着眼点是否一样？比如在CPU上，就是把内存压下去。GPU上有什么guide吗？
Zhe：把东西存在哪儿等问题可以优化。
Kyle：作者想验证GPU和CPU性能优化是否一致，实际思路差不多：如果能优化到cache里，就不用访问内存。Prof. Xue：做正则，沿*FA思路继续走很难突破（带宽、内存）。考虑互联网大数据中，类似分布式、分层检索等思路，分而治之。如GPU，别转化成表，利用强大的计算能力，比如只做比较指令。
Kyle & Xiang：把正则表达式直接转为机器码。虚拟挖掘，非查表。Zhen Chen: 缓存具体指架构中的哪一部分？Xiang：GPU上thread数目量级？
Zhe：512 threads/block, 65535 * 65535 blocks/gridProf. Xue: 对GPU，规则update是大问题。Feng：工业界觉得GPU太贵。
Prof. Xue: I/O，问题更在于负载送不出去。