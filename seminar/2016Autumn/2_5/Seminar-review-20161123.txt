Overview[edit]Title:ï¿¼ ABC: Adaptive Binary Cuttings for Multidimensional Packet Classification
Source: ToN'13
Attendee: Professor Jun Li, Zhen Chen, Zhi Liu, Ju Xing, Ali, Danyang Li, Shuo Wang, Shijie Sun, Dongfang Li, Jun Yang.
Speaker: Qing Lv
Recorder: Danyang Li
Presentation[edit]Background
Packet Classification, Definition
Packet Classification, Solutions
TCAM solutions
Algorithmic solutions
Related Work
Decision tree algorithms
Advantages
Achieve very high throughput when using a deep pipeline and the parallel bucket matching scheme
Simple and efficient implementations by using binary encoding techniques
Incremental updates are also easily supported by decision trees
Flexibly tradeoff between throughput and storage
Disadvantages
Filter duplication
Skewed filter distribution
Observations
Desired properties of DT
The tree consists of as few nodes as possible
The path from the root to any leaf node is short and balanced
A simple cutting procedure
First find the set of optimal cutting points that can balance the distribution of filters and minimize the filter duplication effect
Then sort and register the cutting points
Simply perform a binary search when a DT node is retrieved during the lookups
Algorithm description
Adaptive Binary Cuttings (ABC)
Split the filter set based on the evenness of the filter distribution, rather than the evenness of the cut volumes
Binary encoding scheme, encodes the space-cutting sequence and can directly map to the bit string of the packet header fields.
Discards the notion of the expansion factor
Discards the notion of the bucket size
Algorithm design
Basic idea of ABC
ABC Variation I
Produces a single CST at each DT node
Map each header field to a space dimension
Perform multiple variable-sized cuttings per tree node
Split into two equal-sized subregions along a certain dimension
A full binary tree with k leaf nodes.
ABC Variation II
ABC Variation III
Comparison
Optimization
Reduce Filters Using a Hash Table
Filter Partition on the Protocol Field
Partitioning filters based on duplication factor
Holding filters internally and reversing search order
Evaluation
Scalability on Filter Set Size
Tradeoff of storage and throughput
Sensitivity to Optimizations-Effect
Comparison with HiCutsand HyperCuts
Conclusion
ABC adopts variable sized cuts per decision step to even the filter distribution and reduce the filter duplication.
ABC ensures all the DT nodes have the same size and are fully utilized.
ABC is performance-guided: present the storage budget and then look for best achievable throughput.
ABC is scalable to large filter sets and is sufficient to sustain the real-time packet classification for 10-GbElines.Discussion[edit] ZhiLiu: What value is the 'binth' set to when comparing ABC with hypercuts and Hicuts? Why is ABC so quick? Qing Lv: Not clear from the paper. Since it's hard to compare these three algorithms, the author uses a trade-off graph to show the result. JunLi: This algorithm is more flexible than hypercuts and Hicuts. Ju Xing: Why is the height of the tree in ABC so small?
 Qing Lv: ABC applies more than one cut on the nodes of a single level, so the height is small. Zhen Chen: This algorithm can be implemented  parallelly on hardware. Since most of the instructions can be done by a single instruction of x86.